## Abstract

<!-- Context -->
[RDF-Connect](https://github.com/rdf-connect/) is a novel, language-agnostic framework for building provenance-aware,
streaming data pipelines integrating heterogeneous processors across languages. It aims to facilitate the
construction, maintenance, and reusability of modular, interoperable pipelines for complex, semantically rich data
workflows.
<!-- Need -->
Data processing pipelines are essential for modern data-centric systems, such as knowledge graphs, LLMs, and machine
learning systems. Developers and researchers need flexible, interoperable tools for creating multilingual data
processing pipelines.
<!-- Task -->
To meet this need, we present a comprehensive tutorial that blends conceptual foundations with hands-on experience.
Participants will learn how to use RDF-Connect to design and execute reusable, extensible, and transparent streaming
pipelines.
<br class='screen-only' />
<!-- Object -->
Participants will construct a streaming data processing pipeline from real-world data: generating a weather forecast
knowledge graph for Vienna, Austria. They will: (i) Construct a machine
learning pipeline using processors in multiple programming languages, (ii) Create custom data processors for diverse
endpoints, (iii) Explore provenance tracking using RDF and PROV-O ontology.
<!-- Conclusion -->
By the end of the tutorial, participants from varied backgrounds, including Python, JavaScript, and Java developers,
will gain practical experience building language-agnostic, semantically rich data processing pipelines.
<!-- Perspectives -->
This tutorial not only introduces RDF-Connect but also opens new avenues for interdisciplinary data transformation
strategies in Semantic Web research and development.
